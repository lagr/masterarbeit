% -*- root: ../../main.tex -*- %

\subsection{Architecture Styles} % (fold)
  \label{sub:application_structure}
  Developers of software systems have to cope with factors which impose challenges on them, such as high complexity within their systems, an increased need for integration of internal and external functionality and evolving technologies. Several architectural approaches emerged from the attempt to overcome these challenges. Strîmbei et al consider \emph{monolithic architecture}, \emph{\ac{SOA}} and \emph{Micro-services} to be the most relevant \cite[p.~13]{Strimbei2015Software}.

  \paragraph{Monolithic Architecture} % (fold)
    \label{par:monolithic_architecture}
    Monolithic software systems are characterized by their cohesive structure. Usually, components in a monolith are organized within one programm, often running in one process \cite[p.~35]{Stubbs2015Distributed}. They communicate through shared memory and direct function calls. Monolithic applications are typically written using one programming language \cite[p.~14]{Strimbei2015Software}. In order to cope with increasing workload on a monolithic system, multiple instances of it are run behind a load balancer \cite[p.~35]{Stubbs2015Distributed}.

    The strengths of monolithic architecture lie mostly in its comparably simple demands towards the infrastructure. As the application is run as one entity, deployment and networking are rather simple \cite[p.~35]{Stubbs2015Distributed}. Since data can be shared via memory or disk, monolithic applications can access it faster than it would be the case with networked components \cite[p.~14]{Strimbei2015Software}. \\
    Also, as the interaction between the application's components happens XYZ, the complexity of this interaction is lower compared to interaction between distributed components \cite[p.~14]{Strimbei2015Software}.

    The weaknesses of monolithic architecture stem from its cohesive nature. As its components are usually tightly coupled, changes to one component can affect other parts of the application, which complicates the introduction of new components and the refactoring of existing ones \cite{Stubbs2015Distributed}.
    Components cannot be deployed individually, which hinders reuse of functionality across several applications more difficult and makes scaling of single bootleneck components impossible \cite{Stubbs2015Distributed}. Also, if the application runs in a single process, the failure of one component may bring down the whole application \cite[p.~5]{Newman2015Building}.

    In combination with Docker, a possible solution could look like this: ...
    % paragraph monolithic_architecture (end)

  \paragraph{Service-oriented Architecture} % (fold)
    \label{par:service_oriented_architecture}
    \ac{SOA} is based on the idea that code which provides related business functions can be bundled into one component which offers said functionality to other systems \emph{as a service}, thus avoiding duplicated implementation of the functionalities among these systems \cite[p.8]{Hohpe2004Enterprise}.
    An application may then use several services in order to fulfill its own business function \cite[p.~390]{Papazoglou2007Service}.
    The \ac{OASIS} describes \ac{SOA} as an architectural paradigm that supports the organization and usage of these services \cite{Standards2006Reference}. Each service provider exposes its offered services in a standardized way, \eg using \ac{WSDL}, which can then be utilized by \emph{service consumers} \cite[p.~390]{Papazoglou2007Service}, \cite[p.~17]{Strimbei2015Software}.

    Messages between services in \ac{SOA} are either of direct nature, which is called point-to-point connection, or backed by a message bus, the \ac{ESB} which incorporates the integration logic, \eg on transport and transformation of messages, between services and supports asynchronous messages \cite[p.~393]{Papazoglou2007Service}. While the former leads to tight coupling between the components, which becomes impractical with increasing numbers of endpoints, the latter manages this scenario better \cite[p.~393]{Papazoglou2007Service}.

    On the one hand, \ac{SOA} has some advantages in comparison to monolithic architecture.
    Service consumers do not have to make assumptions - or know - how services work, they only have to rely on the invokation of a service and its result to be formed as expected \cite[p.~390]{Papazoglou2007Service}. As long as the interface and the output of existing services do not change, a service provider may thus be altered or its capabilities be extended without affecting its services' consumers \cite[p.~390]{Papazoglou2007Service}. \ac{SOA} thus enhances an organization’s ability to respond quickly to changes \cite[p.~390]{Papazoglou2007Service}, \cite[p.~254]{Choi2010Implementing}. \\
    Since legacy applications can be provided with appropriate interfaces, SOA can help to integrate and extend them \cite[p.~390]{Papazoglou2007Service}.

    On the other hand, \ac{SOA} has some drawbacks, too.
    For example, the failure of a single service provider may bring down multiple applications that consume its services, if no fallback measures are in place \cite[p.~408f]{Papazoglou2007Service}.
    Also, the overall performance of an application with \ac{SOA} depends on the aggregated performances of the services it uses and their respective interactions \cite[p.~408f]{Papazoglou2007Service}.

    In combination with Docker, a possible solution could look like this: ...
    % paragraph service_oriented_architecture (end)

  \paragraph{Micro-services Architecture} % (fold)
    \label{par:micro_services_architecture}
    The concept of \ac{MSA} is closely related to that of \ac{SOA}, as it also promotes the encapsulation of functionality in standalone services which can be used by other parts of a system. There is unambiguity whether \ac{MSA} is actually a concept on its own -- or rather a specialized application of \ac{SOA} \cite[p.~35]{Stubbs2015Distributed}, \cite[p.~17]{Strimbei2015Software}.
    Stubbs et al describe \ac{MSA} as a distributed system that consists of independent services which are   narrowly focused and thus considered ``lightweight'' \cite[p.~35]{Stubbs2015Distributed}.
    That exact principle has been described as a version of \ac{SOA} before \cite[p.~395]{Papazoglou2007Service}.

    Strîmbei et al created a differentiation between SOA and MSA as a distinct concept based on several sources. They come to the conclusion, that while the communication in \ac{SOA} is synchronous and ``smart but dependency-laden'', \ac{MSA} usually relies on asynchronous, ``dumb, fast messaging'' -- meaning that there is few information on the participating services contained in the messaging infrastructure. Further, they perceive applications in \ac{SOA} to be typically imperative in their programming style, while \ac{MSA} would be in an event-driven programming style \cite[pp.~17-20]{Strimbei2015Software}. They see \ac{SOA} applications as being usually stateful and \ac{MSA} applications as stateless. Finally they characterize the databases in \ac{SOA} as large relational databases and the databases in \ac{MSA} as small, often non-relational databases.

    One benefit of \ac{MSA}, which it shares with \ac{SOA} is that each service can be developed in a language and with a toolset that suits its specific needs, \eg a lower-level language for time-critical but simple tasks or a high-level language with some framework for complex ones, instead of having to find a compromise that suits most of the application  \cite[p.~35]{Stubbs2015Distributed}, \cite[p.~4]{Newman2015Building}, \cite[p.~113]{Thones2015Microservices}.
    The narrow focus of each service makes it less specialized to certain uses, which should theoretically enable better reuse of code \cite[p.~35]{Stubbs2015Distributed}.
    Another positive aspect is the \emph{resilience} of micro-services when it comes to service failures, that is, a single failing service does not render the whole system incapable of working \cite[p.~5]{Newman2015Building}.
    Due to the properties of the \ac{MSA}, micro-services may be deployed, upgraded and scaled individually \cite[p.~116]{Thones2015Microservices}.

    Researchers also see disadvantages and problems that may go hand in hand with the use of \ac{MSA}.
    While \ac{MSA} facilitates deploying parts of an application individually, the overall amount of work required for the deployment of all services is higher and the coordination of the deployments is complexer than the deployment of a monolithic application.
    As services may be unavailable at times, a mechanism has to be in place that allows the discovery of services (such as the \ac{MOM}) \cite[p.~35]{Stubbs2015Distributed}.
    Unless a dedicated service is introduced, there is no central access to the services' logs. Aggregation, analysis and fixing errors is thus more complicated in comparison to monolithic architecture \cite[p.~35]{Stubbs2015Distributed}.
    In order to define the different services, it is necessary to find the right size for each service, \ie the appropriate scope of its functionality. This process is difficult and not needed to this extend in monolithic architectures or \ac{SOA}.

    In combination with Docker, a possible solution could look like this: ...
    % paragraph micro_services_architecture (end)

  <<Possible instances of the wfms components in monolith, soa and msa>>
% subsection application_structure (end)

\subsection{Choice of an Architecture Style} % (fold)
  \label{sub:choice_of_an_achitecture_model}

  One central requirement for the stated objectives is the modularization of the application. It enables the containment of failures, the replacement or upgrading of components at runtime, and the individual scaling of parts of the \ac{WfMS}. The concept of \ac{SOA} and \ac{MSA} inherently requires the modularization of code, while it is optional -- yet, advisable -- in a monolithic architecture.

  While measures can be taken in monolithic applications to cope with failure of components to some degree, if the underlying machine fails or the process dies for whatever reason, the whole application is rendered inoperative \cite[p.~55]{Newman2015Building}. \ac{SOA} and \ac{MSA} both urge to account for the possibility of a non-responding service -- in the first place because of the unreliability of network communication, but that works or any other reason, too. They hence inherently support the objective of resilience better than monolithic architecture.

  Upgrading or replacing components of an application at runtime is possible in each of the presented architectures. In \ac{SOA} the service may be replaced at will by directing requests to an instance of the new version of that service, given that the previously exhibited behavior does not change. The same applies for \ac{MSA}, but as there is no direct messaging, the replaced components just have to adhere to the expected messaging scheme. Monolithic applications may introduce patterns such as dependency injection and dynamic loading to make changes at runtime possible.

  Even though scaling individual parts of an application is a non-trivial task in \ac{SOA} and \ac{MSA}, it is possible. With a monolithic architecture, scaling the whole application is usually easier than in \ac{SOA} and \ac{MSA} -- in most cases, another instance of the application may be started for that purpose --, but it is not possible to scale only those parts of an application where performance bottlenecks arise.

  Facing these considerations, monolithic architecture is ruled out as the favored application structure. In the following, only the decision between \ac{SOA} and \ac{MSA} thus has to be made.

  The Docker Ecosystem facilitates the setup of the infrastructure for a \ac{MSA}. As stated in \ref{par:micro_services_architecture}, the \ac{MOM} itself contains little to no knowledge about the system using it. Thus, the \ac{MOM} and all application components may simply be started in separate containers and connected using an overlay network.

  Docker permits the configuration of restart policies for specific containers. In case that one container crashes, it is restarted with its previous settings, if configured so.

  This reasoning leads to the overall conclusion, that micro-services are the architecture of choice with regards to the chosen objectives.
  % subsection choice_of_an_achitecture_model (end)

\subsection{User Interaction with the System} % (fold)
\label{sub:user_interaction_with_the_system}

  TODO: implemented as REST + MQ for simplicity


  - in monolithic architecture
    -  unified frontend feels natural
  - with micro services
    - two options
      - separate frontends per service
        - more flexibility
        - client somehow has to know the services
      - API gateway pattern to consolidate  services the user can interact with
        - The API gateway handles requests in one of two ways. Some requests are simply proxied/routed to the appropriate service. It handles other requests by fanning out to multiple services.
        - + single entry point for all clients.
        - + decouples internal structure from clients / encapsulates the internal structure of the application
        - - new single point of failure
        - - has to be maintained
    \cite{}
  - options:
% subsection user_interaction_with_the_system (end)

\subsection{Inter-component Communication} % (fold)
\label{sub:inter_component_communication}

  Since all services reside in separate containers, \ie are isolated through namespaces for processes, networks etc, they have to be connected to each other somehow.

  The naïve approach would be to let each container expose its required ports on the host's network interface. In order to communicate with a service in another container, an application would then address the host machine \ac{IP} with the respective port. While this solution appeals because of its simplicity, it comes with considerable drawbacks.
  First, a port can only be used by one application at a time. This poses a problem as soon as a container is run more than once simultaneously, \eg if multiple services require the same database application or a service is started several times for scaling.
  Second, this exposes the services in doubt to requests from any computer that can communicate with the host machine. Unless this is desired behavior, it creates an unnecessary attack surface.

  Another approach is the use of a Docker feature called \emph{links}, which allows to specify direct connections between containers based on their names.
  Docker then creates a secure tunnel between the specified containers and provides information on how the link source container may be addressed to the recipient container. This happens in two ways: it passes along all environment variables of the link source container to the targeted container and updates the \texttt{/etc/hosts} file, which is responsible for manual resolution of hostnames to \ac{IP} addresses.
  Links can be specified when a container is created by referring to one or more already running containers.
  Linked containers can be contacted via their hostname from within the started container.
  While links -- in contrast to the first approach -- allow the same port to be used in different containers and do not expose the containers per se, they too have disadvantages.
  First, and most important, they are static. That is, restarting one container breaks the link functionality. This is problematic, as the re-deployment of a service that relies on links or is linked to may require a domino-like chain of container restarts to restore the linking behavior.
  Second, they do only work on the same host. This solution thus does not support the distributed execution of the \ac{WfMS} micro-services, unless directly related containers, \eg a service and its database, are placed on the same node and all other communication takes place via exposed ports on the respective host machines.
  Third, \ac{all} environment variables that Docker created within a container are passed to any container that links to it, which could post problems regarding security if they contain sensitive data like passwords.

  To cope with these disadvantages, the ambassador pattern was introduced \cite{Docker2016Docker}. The idea behind that pattern is the introduction of a container that acts as an intermediator between two services. This container is linked to both original containers and forwards their requests. In case that one of them needs to be restarted, this container is restarted to restore the connection -- in place of the other container.
  By using two ambassador containers which point to each other, a multi-host setup can be achieved.
  An obvious drawback of this pattern is, that it does not scale well, since each connection requires at least one additional container to be added to the setup. In a clique-like connection setup between five containers \emph{on the same host}, the ambassador pattern would already require ten additional containers.

  While they are still supported under the name \emph{legacy links}, they have been deprecated with the introduction of Docker networks due to their drawbacks.

  Another solution is based on the Docker networking feature set, which was introduced in the end of 2015.
  To be more specific, it utilizes overlay networks, which were briefly presented in \ref{sub:docker_networks}. During the development of this feature set, the \emph{Container Network Model} was added, which allows containers to become member of multiple networks \cite{Tucker2015Docker}.
  This enables the creation of purpose-oriented networks, \eg a ``backend'' and a ``frontend'' network. Containers that are members of both networks can communicate with all containers, while containers which are exclusively connected to the frontend network can only see other containers of this network. This way, one could for example force access to a database to be routed through a container that filters malicious requests.

  This concept can be adapted to suit the needs *TODO WHAT ARE THE NEEDS MY FRIEND* of the prototype: one overarching network is created, which allows all micro-services to communicate with each other. Their containers may are also be members of smaller networks that connect them to their support containers, \eg databases, while keeping these containers isolated from the rest of the \ac{WfMS}. In order to limit access of (probably untrustworthy) third party containers in the workflow to the \ac{WfMS}, a second network may be created in which only containers required for the enactment of workflows are members.
  ** TODO drawbacks? **

  As the last approach has the fewest drawbacks, it should be favored over the other presented ones.
