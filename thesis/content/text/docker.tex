% -*- root: ../../main.tex -*- %

\section{Concepts} % (fold)
\label{sec:docker_concepts}

  First, the concept of software containers will be presented and briefly contrasted against the concept of virtual machines to explain \emph{what} Docker does and to identify the possibilities it offers. Internal constructs of Docker -- images, containers, data volumes, dockerfiles, registries and repositories -- are then introduced in order to provide an understanding on \emph{how} Docker does what it does.

  \subsection{Virtualization} % (fold)
  \label{sub:virtualization_and_software_containers}
    The goal of \emph{virtualization} is to simulate the presence of multiple computers on one machine. This can be beneficial for example to allow applications to run in a controllable environment, isolated from other applications. There are two types of virtualization, one that takes place on the hardware level and another that takes place on the \ac{OS} level \cite{Ruiz2015Performance}.

    \emph{Hardware-level virtualization} is usually driven by a \emph{hypervisor} -- a service that manages virtual machines and provides them with abstracted hardware devices to run on. This hypervisor either runs in the OS of the host machine or directly on its hardware \cite{Ruiz2015Performance}. \\
    Virtual machines, \ie the computers simulated on the host machine, require their own OS to be installed.

    The other kind of virtualization, \emph{OS-level virtualization}, is the one that Docker makes use of.
    It utilizes functions of the host kernel which allow the execution of several isolated userspace instances that share the same kernel, but may differ in terms of their runtime environment, \eg file system or system libraries. These isolated userspace instances are usually called \emph{software containers} or just \emph{containers}. This type of virtualization is therefore also referred to as \emph{container-based virtualization} \cite{Ruiz2015Performance}.

    The isolation and resource management in container-based virtualization on Linux systems are mainly achieved by two mechanisms, \emph{\ac{cgroups}} and \emph{namespaces}. While the former allows to group processes and manage their resource usage, the latter can be used on many system components. Namespaces may be introduced for example on network interfaces, the file system, users and user groups, \acp{PID}, and other components, in order to achieve a fine grained control over the respective isolation \cite{Ruiz2015Performance}.
    Besides Docker, there are several solutions that are based on the aforementioned kernel features, \eg LXC, LXD, lmctfy, systemd-nspawn, etc. \cite{Ruiz2015Performance}. There are ongoing efforts to create a common container standard \cite{Initiative????Open}.

    Many container solutions rely on a mechanism called \emph{\ac{CoW}} to provide a runtime enviroment, which on the one hand lets the containers reuse system libraries and the like while on the other hand limits the container in affecting its surroundings \cite{Docker2016Docker,Pahl2015Containerization}.
    \ac{CoW} is an optimization strategy that makes use of the benefits of both sharing files for read access and copying them to a local version previous to changing them. Processes that require access to a file share the same instance of that file. As soon as one process needs to alter the file, the operating system creates a copy that only the process has access to. All other processes still use the original file \cite{Pahl2015Containerization,Docker2016Docker}.
  % subsection virtualization_and_software_containers (end)

  \subsection{Docker images and containers} % (fold)
  \label{sub:docker_images_and_containers}
    Docker images (referred to as \emph{images} from here on) are the basis for Docker containers. Each image consists of a sequence of layers, with each layer summarizing one \ac{CoW} step, \ie the alterations to the file system that one command causes compared to the previous layer. Each layer is uniquely identifiable, which allows the same layer to be used by several images.

    Docker containers are runtime instances of images.
    In the context of storage, a Docker container can be considered as an image, \ie a set of read-only layers, with a writable layer on top of it -- the \emph{container layer}. Write operations within a container trigger a \ac{CoW} operation which copies the targeted file to the container layer, where the write operation is then performed.
    Besides reducing the amount of space consumed by containers, the \ac{CoW} strategy also reduces the time required to start a container. This is because Docker only has to create the container layer instead of providing a copy of all the files contained in the respective image \cite{Docker2016Docker}. The lifecycle of a container and the set of Docker commands that may influence it are depicted in Figure~\ref{fig:docker_container_lifecycle}.

  % subsection docker_images_and_containers (end)

  \subsection{Data volumes} % (fold)
  \label{sub:data_volumes}
    Any data written to the container layer is deleted as soon as its Docker container is deleted.
    Also, Docker containers that store a lot of data are considerably larger than Docker containers that do not, since the write operations require space in the container layer. This is the reason why data volumes exist -- they are designed to persist data. Data volumes are directories or files that are mounted directly into a Docker container and thus bypass the storage driver \cite{Docker2016Docker}. They are never deleted automatically and therefore must be cleaned up manually if they are not needed anymore \cite{Docker2016Docker}.

    Using a dedicated container that mounts a data volume which is then shared with an application container is a pattern that can be used to keep the application's data across restarts of its container \cite{Docker2016Docker}.

  % subsection data_volumes (end)

  \subsection{Dockerfiles} % (fold)
  \label{sub:dockerfiles}
    Instead of manually creating a container, running commands on it and then commiting it to create an image, a recipe file can be used to instruct Docker to perform these actions -- the \emph{Dockerfile}. In this file, the user states the name of an image that the new image should be based on and the commands that otherwise would be entered manually \cite{Docker2016Docker}.
    To build an image, Docker is given a Dockerfile and a directory with files required for the build, the \emph{build context}, which is usually the directory the Dockerfile is located in. This enables Docker to copy files from the context to some layer within the image, if needed \cite{Docker2016Docker}.
  % subsection dockerfiles (end)

  \subsection{Registries and repositories} % (fold)
  \label{sub:registries_and_repositories}
    A registry stores named Docker images and distributes them on request. Each image may be available in different tagged versions in a registry \cite{Docker2016Docker}.
    Within a registry, images may be organized in collections, which are called \emph{repositories} \cite{Docker2016Docker}.

    Using the commands \texttt{push} and \texttt{pull} in combination with the uniqe \ac{ID} or the name of an image, developers can upload and download it to a registry. If the image name is prepended with the network address or domain of a registry, this registry will be used -- otherwise, Docker tries to perform the action on Docker Hub \cite{Docker2016Docker}.
  % subsection registries_and_repositories (end)

  \subsection{Docker Engine} % (fold)
  \label{sub:docker_engine}

   The Docker Engine forms the core of Docker as it provides access to the features described in the rest of this section.
   The user can use the engine for example to monitor and change the status of a container, \eg as depicted in Figure~\ref{fig:docker_container_lifecycle}, manage the images on a host or administrate the available networks.

   Docker Engine makes use of a client-server architecture: it features a daemon, \ie a background process that is not directly controlled by the user, which provides the functionality and a client that controls said daemon \cite{Docker????DockerCom}. Both client and daemon may run on the same system, or be connected remotely through a \ac{REST} \ac{API} \cite{Docker2016Docker}. By passing the network addresses of nodes running the Docker daemon anlong commands issued to a client, it is thus possible to control several Docker hosts from a single client. An abstraction to this process is provided by Docker Swarm.
  % subsection docker_engine (end)


  \subsection{Docker networking} % (fold)
  \label{sub:docker_networks}
    Since version 1.9, which was released in November 2015, Docker features virtual networks in order to isolate containers concerning their network connections, but at the same time allow containers to communicate with the host, each other, and the outside world. These networks are based on virtual interfaces and are managed by the Docker daemon. Containers may be connected to multiple networks at the same time \cite{Docker2016Docker}.

    By default, Docker installs three networks: a \emph{bridge} network, a \emph{host} network, and a \emph{none} network.
    The \emph{bridge} network, titled \emph{docker0}, is a subnetwork that is connected to the host's networks. Docker connects containers to this network if not instructed otherwise. Containers that are members of this network can communicate with each other by using their respective \ac{IP} addresses. They also may expose ports that can be mapped to the host's network, which makes the applications that run in them accessible from the outside.
    The \emph{host} network represents the actual host's network. If containers are assigned to this network, they will be placed in the host's network stack, \ie all network interfaces defined on the host are available to the container \cite{Docker2016Docker}.
    The \emph{none} network provides containers with their own network stack. Containers that are only members of the \emph{none} network are completely isolated in regards to network communication, unless futher configuration is undertaken \cite{Docker2016Docker}.

    Besides the network types mentioned above, Docker features another type of network, the \emph{overlay} network. Overlay networks are virtual networks that are based on existing network connections. They are intended to simplify the communication between containers running on multiple hosts which, in turn, run on multiple machines themselves. If a container is member of an overlay network, it is able to communicate with all other containers that are also part of this network, no matter which Docker host (or host machine) they are running on \cite{Docker2016Docker}.
    Docker's overlay network requires a key-value store to be present in order to persist information on its own state, \eg on lower level networks that it relies on, network members, etc.
  % subsection docker_networks (end)
% section concepts (end)


\section{Docker ecosystem} % (fold)
\label{sec:docker_ecosystem}

   Around the Docker Engine, several other solutions have been developed to cope with different specialized tasks that are asscociated with building and running containers. In the following, a selection of these solutions will be introduced briefly.

  \subsection{Docker Swarm} % (fold)
  \label{sub:docker_swarm}
    Docker Swarm allows applications which rely on several Docker containers to be run on a cluster of machines. It provides an abstraction that lets a set of Docker Engines behave like a single Docker Engine. Further it assigns containers to a specific host for executiion based on given rules \cite{Docker2016Dockera}.

    A swarm setup typically consists of one or more \emph{swarm managers}, multiple Docker hosts, and, in case that no remote discovery service is used, a local discovery service. By default, every new container is assigned to a swarm-specific overlay network \cite{Docker2016Docker}.

    Docker Swarm provides two kinds of mechanisms for the assignment of containers to Docker hosts, \emph{strategies} and \emph{filters}. Strategies tell Docker how to rank hosts for assignment by some specified criteria, \eg available resources of a host or number of already deployed containers on it.
    Filters allow to specify rules, which Docker tries to apply when searching for an assignment target. Possible rules could for example be matchers for the host's name or identifier, its \ac{OS}, or for custom tags, which may describe the host's role or properties like size of attached storage. It is also possible to declare the affinity of certain containers or images for being deployed on the same host \cite{Docker2016Docker}. Filters are examined in more detail in \ref{sub:execution_scheduling}.
  % subsection docker_swarm (end)

  \subsection{Docker Machine} % (fold)
  \label{sub:docker_machine}
    The Docker Machine tool is designed to facilitate the setup of Docker hosts. In order to fulfill this goal, Docker Machine creates one virtual machine per requested host \cite{Docker2016Dockera,Docker2016Docker}. This has several reasons. First, this proceeding allows several Docker hosts to run on the same computer while prohibiting them from interfering with each other. Second, it enables computers with \acp{OS} that natively do not support Docker and Docker containers, to act as a Docker host \cite{Docker2016Docker}. And third, as the virtual machine image is known, it lets the setup procedure make assumptions on its environment, which simplifies the installation and configuration of the Docker Engine.
  % subsection docker_machine (end)

  \subsection{Docker Compose} % (fold)
  \label{sub:docker_compose}
    Docker Compose is a tool that enables the user to specify and run applications that consist of many containers. Similar to the way an image is described in a Dockerfile, the user lists the required containers and their respective run configuration in a descriptive file. Docker Compose interprets this file and sets the containers up accordingly \cite{Docker2016Dockera}.

    Docker Compose files supports a wide range of commands to facilitate the deployment and management of containers. Only the most important ones for this thesis are thus presented briefly.
    Using the keyword \texttt{networks} allows to specify networks and their configurations that should be created by Docker prior to the start of the containers. If it is nested within a service configuration, the networks that a container shall be connected to can be listed.
    The keyword \texttt{image} can be used to specify the image that should be used for the creation of a container. In combination with the keyword \texttt{build}, Docker can be instructed to construct that very image according to a specified configuration before the container is instanciated from it \cite{Docker2016Docker}.

    When the \texttt{up} command is called, Compose first builds or pulls all required images and creates the specified networks if they do not exist. It then iterates over the specified containers in the order defined by their mutual dependencies and starts containers if they are stopped or missing or recreates them if a newer version of their underlying image is available on the node \cite{Docker2016Docker}.

  % subsection docker_compose (end)

  \subsection{Docker Hub} % (fold)
  \label{sub:docker_hub}
    Docker Hub is a service that allows to store, browse and distribute Docker images. The service is free of charge for public repositories and offers paid private repositories. Using the Docker Engine client or the web interface, users can search for public images and download them \cite[p.~4]{Boettiger2015Introduction}. GitHub repositories that contain a build context and an appropriate Dockerfile can be linked to a Docker Hub repository to let Docker Hub perform automated image builds if code is updated on these repositories \cite{Docker2016Docker}.

  % subsection docker_hub (end)

% section docker_ecosystem (end)
