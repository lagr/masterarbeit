% -*- root: ../../main.tex -*- %

\section{Concepts} % (fold)
\label{sec:docker_concepts}

  First, the concept of software containers will be presented and contrasted against the concept of virtual machines. This is necessary to understand \emph{what} Docker does and to identify possibilities it gives. Then, internal constructs of Docker -- images, containers, data volumes, dockerfiles, registries and repositories -- are explained, in order to provide an understanding on \emph{how} Docker does what it does.

  \subsection{Virtualization and Software Containers} % (fold)
  \label{sub:virtualization_and_software_containers}
    The goal of \emph{virtualization} is to simulate the presence of multiple computers on one machine. The use of this is XXX. There are two kinds of virtualization, one that takes place on the hardware level and another that takes place on the \ac{OS} level \cite{Ruiz2015Performance}.

    \paragraph{Hardware-level virtualization} % (fold)
    \label{par:hardware_level_virtualization}
      In most cases when speaking about virtualization, \emph{hardware-level virtualization} is referred to. It is usually driven by a \emph{hypervisor} -- a service that manages virtual machines and provides them with abstracted hardware devices to run on. This hypervisor either either runs in the OS of the host machine or directly on its hardware \cite{Ruiz2015Performance}. \\
      The virtual machines, \ie the computers simulated on the host machine, require their own OS to be installed.
    % paragraph hardware_level_virtualization (end)

    \paragraph{OS-level virtualization -- or container-based virtualization} % (fold)
    \label{par:os_level_virtualization}
      The other kind of virtualization, \emph{OS-level virtualization}, is the one that Docker makes use of.
      It utilizes functions of the host kernel which allow the execution of several isolated userspace instances that share the same kernel, but may differ in terms of their runtime environment, \eg file system or system libraries. These isolated userspace instances are usually called \emph{software containers} or just \emph{containers}. This type of virtualization is therefore also referred to as \emph{container-based virtualization} \cite{Ruiz2015Performance}. \\

      The isolation and resource management in container-based virtualization on Linux systems are mainly achieved by two mechanisms, \emph{\ac{cgroups}} and \emph{namespaces}. While the former allows to group processes and manage their resource usage, the latter can be used on many system components. Namespaces may be introduced for example on network interfaces, the file system, users and user groups, \acp{PID}, and other components, in order to achieve a fine grained control over the respective isolation \cite{Ruiz2015Performance}. \\
      Besides Docker, there are several solutions that are all based on the aforementioned kernel features, \eg LXC, LXD, lmctfy, systemd-nspawn, etc \cite{Ruiz2015Performance}. There are ongoing efforts to create a common container standard \cite{Initiative????Open}.

      Many container solutions rely on a strategy called \emph{\ac{CoW}} to provide a runtime enviroment, which on the one hand lets the containers reuse system libraries and the like while on the other hand limits the container in affecting its surroundings \cite{Docker????Dockera,Pahl2015Containerization}. This strategy is explained in a more detailed fashion in \ref{sub:docker_images_and_containers} on the example of Docker.

    % paragraph os_level_virtualization (end)
  % subsection virtualization_and_software_containers (end)

  \subsection{Docker Images and Containers} % (fold)
  \label{sub:docker_images_and_containers}
    \ac{CoW} is a strategy which makes use of the benefits of both sharing files for read access and copying them to a local version previous to changing them. Processes that require access to a file share the same instance of that file. As soon as one process needs to alter the file, the operating system creates a copy to which only the process has access to. All other processes still use the original file \cite{Pahl2015Containerization,Docker????Dockera}.

    Docker images (referred to as just \emph{images} from here) are the basis for Docker containers. Each image consists of a sequence of layers, where each layer summarizes one \ac{CoW} step, \ie the alterations to the file system that one command causes compared to the previous layer. Each layer is uniquely identifiable, which allows the same layer to be used by several images.

    Docker containers are runtime instances of images.
    In the context of storage, a Docker container can be considered as an image, \ie a set of read-only layers, with a writable layer on top of it -- the \emph{container layer}. Write operations within a container trigger a \ac{CoW} operation which copies the targeted file to the container layer, where the write operation is then performed. \\
    Besides reducing the amount of space consumed by containers, the \ac{CoW} strategy also reduces the time required to start a container. This is because Docker only has to create the container layer instead of providing a copy of all the filed contained in the respective image \cite{Docker????Dockera}.

    - *lifecycle of a docker container here*
  % subsection docker_images_and_containers (end)

  \subsection{Data Volumes} % (fold)
  \label{sub:data_volumes}
    Any data written to the container layer is deleted as soon as its Docker container is deleted.
    Also, Docker containers that store a lot of data are considerably larger than Docker containers that do not, since the write operations require space in the container layer. This is the reason why data volumes exist -- they are designed to persist data. Data volumes are directories or files that are mounted directly into a Docker container and thus bypass the storage driver \cite{Docker????Docker}. They are never deleted automatically and therefore must be cleaned up manually when they are not needed anymore \cite{Docker????Dockera}.

  % subsection data_volumes (end)

  \subsection{Dockerfiles} % (fold)
  \label{sub:dockerfiles}
    Instead of manually creating a container, running commands on it and then commiting it to create an image, Docker can be instructed by a recipe file -- the \emph{dockerfile}. In this file, the user states an image that the new image should be based on and the commands that otherwise would be entered manually \cite{Docker????Docker}. \\
    To build an image, Docker is given a Dockerfile and a directory with files required for the build, the \emph{context}, which is usually the directory the Dockerfile is located in. This enables Docker to copy files from the context to some layer within the image, if needed \cite{Docker????Docker}.

  % subsection dockerfiles (end)

  \subsection{Registries and Repositories} % (fold)
  \label{sub:registries_and_repositories}
    A registry stores named Docker images and distributes them on request. Each image may be available in different tagged versions in a registry \cite{Docker????Dockera}. \\
    Within a registry, images may be organized in collections, which are called \emph{repositories} \cite{Docker????Docker}.

  % subsection registries_and_repositories (end)

  \subsection{Docker Networking} % (fold)
  \label{sub:docker_networks}
    As mentioned in \ref{sub:virtualization_and_software_containers}, Docker features virtual networks in order to isolate containers in this regard, but at the same time allow containers to communicate with the host, each other and the outside world. These networks are based on virtual interfaces and are managed by the Docker daemon. Containers may be member of multiple networks at the same time \cite{Docker????Dockera}.

    By default, Docker installs three networks: a \emph{bridge} network, a \emph{host} network, and a \emph{none} network. \\
    The \emph{bridge} network, titled \emph{docker0}, is a subnetwork that is connected to the host's networks. Docker connects containers to this network if it is not instructed otherwise. Containers that are membsers of this network can communicate with each other by using their respective \ac{IP} addresses. They also may expose ports that can be mapped to the hosts network, which makes applications in them accessible from the outside. \\
    The \emph{host} network represents the actual hosts network. If containers are assigned to this network, they will be placed in the hosts network stack, \ie all network interfaces defined on the host are available to the container \cite{Docker????Dockera}. \\
    The \emph{none} network provides containers with their own network stack. Containers that are only members of the \emph{none} network are completely isolated in regards to network communication, unless futher configuration is undertaken \cite{Docker????Dockera}.

    Besides the network types mentioned above, Docker features another type of network, the \emph{overlay} network. Overlay networks are virtual networks that are based on existing network connections. They are intended to simplify the communication between containers running on multiple hosts which, in turn, run on multiple machines themselves. If a container is member of an overlay network, it is able to communicate with all other containers that are also part of this network, no matter which Docker host (or host machine) they are running on \cite{Docker????Dockera}. \\
    Docker's overlay network requires a key-value store to be present in order to persist information on its own state, \eg on lower level networks that it relies on, network members, etc.

      %- service discovery

      % The benefits of service discovery are very well known: it’s a great way to remove the need to manually specify topology network information (IP address and port) of an environment (dev, prod, etc.) when launching containers.

      % Docker links force you to use environment variables or “placeholder” hostnames in the application image configuration files. This is a great way to allow the image to be reusable across different environments. Both environment variables and DNS hostnames are supported in virtually any programming language, needing very little change to the application codebase.


    % The intention of these networks is to segregate services such that the only things on a network are things that need to talk to each other. This means in practice you should have lots of networks with small amounts of containers in them. Networks are all isolated from each other. If two containers are not on the same network, they cannot talk.  http://www.container42.com/2015/10/30/docker-networking-reborn/

    % Service discovery is one component of in an overall strategy aimed at making container deployments scalable and flexible. Service discovery is used so that containers can find out about the environment they have been introduced to without administrator intervention. They can find connection information for the components they must interact with, and they can register themselves so that other tools know that they are available. These tools also typically function as globally distributed configuration stores where arbitrary config settings can be set for the services operating in your infrastructure. https://www.digitalocean.com/community/tutorials/the-docker-ecosystem-an-introduction-to-common-components

  % subsection docker_networks (end)

% section concepts (end)

\section{Docker Engine} % (fold)
\label{sec:docker_engine}

 The Docker Engine forms the core of Docker.
 Docker uses a client-server architecture: it features a daemon which provides the functionality and a client that controls said daemon \cite{Docker????DockerCom}. Together, they enable the user to work with Docker containers. Both the client and the daemon may run on the same system, or be connected remotely via sockets or through a \ac{REST} \ac{API} \cite{Docker????Dockera}.

% section docker_engine (end)

\section{Docker Ecosystem} % (fold)
\label{sec:docker_ecosystem}

  Around the Docker Engine, several other solutions have evolved to cope with different specialized tasks that are asscociated with building and running containers. In the following, a selection from these solutions will be introduced briefly.

  \subsection{Docker Swarm} % (fold)
  \label{sub:docker_swarm}
    Docker Swarm allows applications which rely on several Docker containers to be run on a cluster of machines. It provides an abstraction that lets a set of Docker Engines behave like a single Docker Engine. Further it features a mechanism that automatically assigns container to a specific host based on given rules \cite{Docker????Dockerb}.

    A swarm setup typically consists of one or more \emph{swarm managers}, multiple Docker hosts, and, in case that no remote discovery service is used, a local discovery service. By default, every new container is assigned to a swarm-specific overlay network \cite{Docker????Dockera}.

    Docker Swarm provides two kinds of mechanisms for the assignment of containers to Docker hosts, \emph{filters} and \emph{strategies}. Strategies tell Docker how to rank hosts for assignment by some specified criteria, \eg resource usage or number of deployed containers. \\
    Filters allow to specify rules, which Docker tries to apply when searching for an assignment target. Possible rules could for example be matchers for the host's name or identifier, its \ac{OS}, or for custom tags, which may describe the host's role or properties like size of attached storage. It is also possible to declare the affinity of certain containers or images for being deployed on the same host \cite{Docker????Dockera}.

  % subsection docker_swarm (end)

  \subsection{Docker Machine} % (fold)
  \label{sub:docker_machine}
    The goal of the Docker Machine tool is to facilitate the setup of Docker hosts. In order to fulfill this goal, Docker Machine creates one virtual machine per requested host \cite{Docker????Dockerb,Docker????Dockera}. This has several reasons. First, this proceeding allows several Docker hosts to run on the same machine without having them interfere with each other. Second, it enables machines with \acp{OS}, which natively do not support Docker and Docker containers, to act as a host \cite{Docker????Dockera}. And third, as the virtual machine image is known, it lets the setup procedure make assumptions on its environment, which simplifies the installation and configuration of the Docker Engine.
  % subsection docker_machine (end)

  \subsection{Docker Compose} % (fold)
  \label{sub:docker_compose}
    Docker Compose is a tool that enables the user to specify and run applications that consist of many containers. Similar to the way an image is described in a Dockerfile, the user lists the required containers and their respective run configuration in a YAML (?) file. Docker Compose interprets this file and sets the containers up accordingly \cite{Docker????Dockerb}.

  % subsection docker_compose (end)

  \subsection{Docker Hub} % (fold)
  \label{sub:docker_hub}

  % subsection docker_hub (end)

% section docker_ecosystem (end)
