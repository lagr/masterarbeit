% -*- root: ../../main.tex -*- %

\subsection{Workflow and activity images} % (fold)
\label{sub:workflow_activity_images}
  To reap the benefits of the layering mechanism, the structure of the images should be chosen with care. Layers should be created in a way that enables reusability among the different use cases and they should be ordered by the frequency that they are likely to be changed by.

  The proposed structure of workflow and activity images, which is depicted in Figure~\ref{fig:layers_for_element_wrapping_containers} and reflected in the respective Dockerfiles \ref{lst:dockerfile_for_activity_base_image} and \ref{lst:dockerfile_for_workflow_base_image}, is thus as follows.

  The proposed structure consists on three images which should build on each other consecutively, as they are meant to be increasingly specialized. The first image should provide the runtime environment. This image could be provided by a third-party vendor that specializes in building such images, \ie an \ac{OS} community or framework developers. Based on this image, a generic activity image \texttt{ac\_base} (and, for $*_{SEPC}^{*}$, a generic workflow image \texttt{wf\_base}) should be created. Such an image can be extended with element-specific information for each element of a workflow when that workflow is exported for deployment, to obtain the uppermost images \texttt{ac\_\$activity\_id} (and \texttt{wf\_\$workflow\_id}). An instance of this last image would then be a container with a suitable name of the form \texttt{aci\_\$activity\_instance\_id} (and respectively \texttt{wfi\_\$workflow\_instance\_id}).

  \begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{content/images/layer_concept-crop.pdf}
    \caption{Layer Structure for Activity/Workflow Images}
    \label{fig:layers_for_element_wrapping_containers}
  \end{figure}

  Regarded in a more detail, the images' structure should look as follows.
  The foundation should be formed by \emph{runtime environment layers}, as they are expected to change  seldom and are required by all derived images. Usually, these layers contain an \ac{OS}, common libraries and utility programs.

  The layers that form the \texttt{*\_base} images can be separated in two groups, \emph{common layers} and \emph{element-type-specific layers}. The \emph{element type} refers to either activity or workflow.
  The common layers should be created on top of these runtime environment layers. They are intended to contain the effects of invoked commands, added directory structures and files which are required by both activity images and workflow images. Even though these layers are not explicitly named, they will be stored by Docker in its cache and used during the build process of similar images.
  In the next step, element-type-specific layers should be added. These layers are meant to contain data that is required for the execution of an activity \emph{or} a workflow, for example scripts which perform validation tasks (if not provided by a service) or general-purpose data transformation.

  The element-specific layer, which is added in the course of the export of an element (activity or workflow), contains files that are particular to single activities or workflows. In an activity image, this layer would contain the activity configuration and the schemas for data validation. In a workflow images, for example, it would contain the process definition.

  By instantiating the resulting image a container is created at runtime, which owns the uppermost, writable layer. This is where the activity or workflow may store data during execution.

  At the time of writing, Docker registries do not reuse layers across repository borders during uploads yet -- even though it is a proposed feature \cite{Mcgowan2015Proposal}. In order to benefit from the layering in the previously described way, it is thus necessary to let all activity images reside in the same repository by tagging them in the format
  \\ [0.5ex]
  \centerline{\texttt{\$repository\_url/activity}}
  \\ [0.5ex]
  and using the respective activity's \ac{ID} as a version tag to differentiate between them. They can then be referred to as
  \\ [0.5ex]
  \centerline{\texttt{\$repository\_url/activity:ac\_\$activity\_id}}
  \\ [0.5ex]
  Analogously, this is done with workflow images. Since it implies losing the internal image versioning mechanism, this solution should only be used as a workaround until cross-repository sharing of layers is possible.

  The workflow instance is structured as depicted in \ref{fig:class_diagram_wf_base}. It contains the classes \texttt{ProcessInstance} and \texttt{ActivityInstance} which coordinate the enactment of the workflow instance, and the utility classes \texttt{ProcessDefinition}, \texttt{FileHelper}, \texttt{Configuration}, and \texttt{Validator}, which provide auxiliary functionality.
  \texttt{ProcessDefinition} parses the process definition file and creates objects for the process definition itself and its contained activities to facilitate accessing their respective properties.
  \texttt{Configuration} wraps the access to relevant environment variables in methods, which may provide defaults for missing values. Everything that is related to file system access, \eg constructing paths, linking and creating directories etc, is performed by the \texttt{FileHelper} class. The \texttt{Validator} is used to validate the workflow instance's input data.

  The activity image contains the classes \texttt{ActivityInstance}, \texttt{WorklistClient}, \texttt{ContainerInvocation}, \texttt{SubworkflowInvocation}, \texttt{FileHelper}, \texttt{Configuration}, and \texttt{Validator}, as depicted in \ref{fig:uml_class_diagram_ac_base}.
  \texttt{FileHelper}, \texttt{Configuration}, and \texttt{Validator} have the same functionalities as their counterparts in the workflow image. The image should be able to start a sub-workflow or a third-party container, or create a worklist item and wait for its completion. The classes \texttt{SubworkflowInvocation}, \texttt{ContainerInvocation}, and \texttt{WorklistClient} encompass these functionalities respectively. The decision as to which class is invoked for the actual functionality is made by the \texttt{Instance} class.

% subsection workflow_activity_images (end)

\subsection{Communication} % (fold)
  \label{sub:application_level_communication}
  The considerations in \ref{sub:inter_component_communication} are directed at finding a model for low-level communication, \ie the communication between containers. In the following, an application-level solution for the inter-service communication is chosen. To harmonize with the objectives worked out in \ref{sec:determination_of_objectives}, the solution should  support the exchange of service versions on a running system, it should be able to handle service failures, and it should allow the dynamic addition of servers.

  \ac{MSA} advocates the use of messaging on a general-purpose channel which does not incorporate any application logic \cite[pp.~20]{Strimbei2015Software}. Such messaging could be either be performed directly between services using \ac{REST} calls over \ac{HTTP} or via \ac{MOM} \cite[pp.~23-24, p.~30]{Newman2015Building}.

  The principle of \ac{REST} is the abstraction of a services' functionalities into \emph{resources}, nameable pieces of information, whose state and value can be exposed in the form of a \emph{representation} and altered using a specific set of actions \cite[p.~3]{Fielding2002Principled}.

  A common protocol used by \ac{MOM} is \ac{AMQP}. Central elements of \ac{AMQP} are \emph{exchanges} and \emph{message queues}. An exchange receives messages and forwards them to specific queues based on a set of rules or criteria \cite[p.~88]{Vinoski2006Advanced}. These rules are called \emph{bindings}.
  Message queues store messages and send them to those consumers which have signaled an interest in these queues \cite[p.~88]{Vinoski2006Advanced}. Multiple clients, called \emph{consumers}, may be subscribed to a queue.

  Servers can be added dynamically in both variants. In the \ac{REST} variant, services on new servers can register at a service discovery tool, which is then queried by client services prior to sending requests \cite{Richardson2015Service}. If \ac{MOM} is used, services on added servers may subscribe to relevant message queues, given that the middleware's network location is known to the service.

  \ac{REST} based communication takes place between two components, whereas the actual target of a request may be determined by an intermediate proxy server \cite[p.~6]{Fielding2002Principled}. However, in the end both parties involved have to be present and available for communication.
  In contrast to that, \ac{MOM} that implements \ac{AMQP} permits to store messages until they are delivered. In case of service failure, the messages will remain on the queue and can be received by the restarted service or another instance of that service. This makes \ac{MOM} more favorable than \ac{REST} calls over \ac{HTTP} in terms of failure resilience.

  Another objective determined in \ref{sec:determination_of_objectives} is that components of the \ac{WfMS} should be alterable without a full system restart.
  In a setup that uses \ac{REST} calls, this can be accomplished by starting an instance of the new version and instructing the service discovery tool to forward upcoming requests to the address of that service version.
  \ac{AMQP} allows the consumers of multiple instances of a service to be subscribed to the same queue, which enables the creation of worker pools that can be scaled to suit the workload.
  In order to deploy a new version of a service this new version can be started in parallel to the old version -- as long as the externally perceived behavior of the currently used functions of that service has not changed. The two versions of the service will work on incoming requests in round robin if they are subscribed to the same queue. If the new version of the service is deemed stable, the old version may be shut down.

  With regards to the above considerations, a communication structure based on \ac{MOM} that implements \ac{AMQP} is chosen for the prototype.
% subsection application_level_communication (end)

\subsection{Components} % (fold)
  \label{sub:components}
  As noted in \ref{par:micro_services_architecture}, one of the downsides of \ac{MSA} is that it is crucial to determine suitable service boundaries. In case of \acp{WfMS}, the identification of system components by the \ac{WfMC} for their reference model is interpreted as such an analysis for this thesis. Based on those components further micro-services for the prototype are identified. As presented in \ref{sub:system_components}, the \ac{WfMC} identified the following components \cite[p.~13]{Hollingsworth1995Wfmc}:
    \begin{itemize}[nosep]
      \item Software Components
        \begin{itemize}[nosep]
          \item Definition Tool %
          \item User Interface
          \item Workflow Engine(s)
          \item Worklists Handler %
          \item (Administration and Monitoring Tool) %
        \end{itemize}
      \item Data Components
        \begin{itemize}[nosep]
          \item Organization Data %
          \item Process Definitions Data %
          \item Workflow Control Data
          \item Workflow Relevant Data %
          \item Worklists Data %
        \end{itemize}
    \end{itemize}

  The administration and monitoring component can be subdivided in an organization management service and an infrastructure management service, as these functionalities are completely independent from each other.

  According to the \ac{WfMC}'s description, the definition tool, the worklists handler and the organization management tool each utilize one data component respectively. Combined with its respective datastore, each of them can be considered an autonomous micro-service since each would be able to provide its functionality without any further service.

  The workflow control data component can be considered to be part of a workflow engine service.
  Depending on the chosen mode for the enactment, workflow relevant data is either managed by the workflow engine service, too, or accounted for by a data volume ($*_{*}^{DV}$). Only in the $*_{*}^{SER}$ variant, a dedicated service for its management and storage is needed.

  According to the decision to use the \ac{API} gateway pattern (\ref{sub:user_interaction_with_the_system}) to hide the internal system structure from its users, the two contact points -- one for administrative work and one for end-user work -- are realized using an appropriate gateway. The \emph{developer gateway} enables requests to the definition service, the infrastructure service and the organization management service through a \ac{GUI}. The \emph{user gateway} emits requests to the worklists service which are also issued through a \ac{GUI}.

  In addition to the services derived above, the need for some additional services originates from considerations regarding the use of Docker for workflow execution in Section~\ref{sec:docker_for_wf_execution} and the objectives that were stated in \ref{sec:determination_of_objectives}.
  One of these objectives is that the distribution of images can be performed in an automated way. A Docker image registry in combination with a service that uses it can be used for the distribution of images to all nodes. Unless an external service such as Docker Hub is used, an own registry service should be a component of the \ac{WfMS}.
  The decision made in \ref{sub:application_level_communication} to use \ac{MOM} for the communication between services creates the need for a service which acts as such middleware.
  To meet the requirement of automatically distributed images, a provisioning service should be introduced, which performs the appropriate actions. An infrastructure management service could be used to monitor the status and properties of the available nodes in the swarm.

  Besides the major components, independent functionalities which are frequently used could be singled out to separate services. For example, a micro-service that addresses the validation of input and output data might be extracted. Given a dataset and a schema, such a service would be able to perform its task autonomously. As validation is a frequently recurring action in the execution of workflows -- before and after each activity and workflow -- it is beneficial to be able to scale the execution of this task independently.

  In the following, the resulting set of services is presented.

  \subsubsection{Workflow Definition Service} % (fold)
    \label{subs:workflow_definition_service}

    The workflow definition service encompasses the functions envisioned by the \ac{WfMC} as \emph{process definition tools}, \ie it is concerned with the analysis, modeling, description and documentation of business processes in form of workflow models and their process definitions. It further manages the assignment of activities to roles.

    With regards to its functional scope, the workflow definition service is also the service that handles the transformation of workflows into their distributable format, \eg a self-contained description file or Docker images. In case of the latter, the workflow definition service would require access to a Docker daemon in order to perform the export. Once a workflow is transformed, the service should publish it. The transformations of workflows is performed by the \texttt{ImageBuilder} class, which relies on the \texttt{ProcessDefinitionImageSerializer} for the serialization of the process definition. The logic required for publishing the images is defined in the \texttt{ImageManager} class.


    As depicted in Figure~\ref{fig:uml_class_diagram_for_the_definition_service},
    the service has the model classes \texttt{Workflow}, \texttt{Activity}, \texttt{ProcessDefinition}, and \texttt{ControlFlow}, which provide the object-relational mapping for the respective objects. The roles assigned to activities have only to be dealt with in the form of unique identifiers, relying on the assumption that components which have to use them may resolve these identiefiers themselves.

    As a user interface is provided by the developer gateway service; the workflow definition service thus does not offer its own user interface, but rather exposes its functionality via the \ac{MOM}. This allows workflow definitions to be created and altered by other services, \eg an conversion service which translates other process definition formats or some feedback mechanism that alters workflows based on their execution performance -- or a gateway service that provides a user interface.

    \begin{figure}[tbp]
      \centering
      \includegraphics[width=0.95\textwidth]{content/images/class_diagram_definition-crop.pdf}
      \caption{UML Class Diagram for the Workflow Definition Service}
      \label{fig:uml_class_diagram_for_the_definition_service}
    \end{figure}

    In order react to requests of other services, the workflow definition service features consumer classes, which perform the required actions and publish a response, if required. \texttt{WorkflowConsumer}, \texttt{ActivityConsumer}, \texttt{ProcessDefinitionConsumer}, and \texttt{ControlFlowConsumer} response to \ac{CRUD} and index requests. The \texttt{WorkflowConsumer} additionally provides the means to react to requests for the export of a workflow.

    There exist two classes in this service which deal with the serialization of objects.
    The serialization of a workflow with its components nested inside takes place in the \texttt{WorkflowFullSerializer}. Such a serialized version is required to avoid separate requests when the workflow is requested for modeling. The \texttt{ProcessDefinitionImageSerializer} is used to generate a serialized version of a process definition which can then be incorporated in workflow images.

    Since one of the previously determined requirements for the prototype is that developers should be supported to use third-party images, the workflow definition service further reacts to relevant requests in the \texttt{DockerConsumer} by initiating a search for images with a specified name on Docker Hub.

    In order to be able to communicate with the \ac{MOM}, the workflow definition service is connected to the \texttt{wmfs\_backend} network. As it is not involved in the enactment and is not intended to be available to external applications, it is neither member of the \texttt{enactment} nor the \texttt{frontend} network.
    % subsubsection workflow_definition_service (end)

  \subsubsection{Organization Management Service} % (fold)
    \label{subs:organization_management_service}
    The organization management service is part of the \emph{administration and monitoring tools}.
    As its name suggests, its functionality is aimed at the management of actors within an organization and their mutual relationships. The service may be queried for users or roles, or to authenticate users for the use of the \ac{WfMS}.

    As depicted in Figure~\ref{fig:uml_class_diagram_for_the_organization_service}, the service consists of the classes \texttt{User}, \texttt{Role}m \texttt{UserConsumer}, and \texttt{RoleConsumer}.
    The model classes \texttt{User} and \texttt{Role} provide the object-relational mapping for the database, while the \texttt{UserConsumer} and \texttt{RoleConsumer} classes enable the service to react to \ac{CRUD} and index requests that concern these objects.

    \begin{figure}[htbp]
      \centering
      \includegraphics[width=0.65\textwidth]{content/images/class_diagram_organization-crop.pdf}
      \caption{UML Class Diagram for the Organization Management Service}
      \label{fig:uml_class_diagram_for_the_organization_service}
    \end{figure}

    Like the workflow definition service, the organization management service is connected to the \texttt{wmfs\_backend} network to be able to communicate with the \ac{MOM}.
    % subsubsection organization_management_service (end)

  \subsubsection{Worklist Service} % (fold)
    \label{subs:worklist_service}
    The sole responsibility of this service is the management of users' worklists. It handles \ac{CRUD} requests for worklist items and publishes the data submitted to it by users to the other services. If a role is deleted, it should remove the worklist item or reassign it to another role. The former tasks are performed by the \texttt{WorklistConsumer}, which reacts to related events. The latter task is in the responsibility of the \texttt{RoleConsumer}, which reacts to the deletion of a role. The worklist items' object-relational mapping is performed by the \texttt{WorklistItem} model class.
    % subsubsection worklist_service (end)

  \subsubsection{Workflow Engine Service} % (fold)
    \label{subs:workflow_engine_service}
    % In wide parts, the workflow engine service is congruent to the \emph{workflow engine} component identified by the \ac{WfMC} in terms of functionality, which is described in \ref{par:workflow_engine}.
    The way how Docker is utilized for the workflow enactment chosen in \ref{sec:docker_for_wf_execution} has an impact on the range of functionalities that this service has. In case of the selected $G_{SEPC}^{DV}$ variant, the engine is responsible for the creation of a workflow instance container from the appropriate workflow image on a suitable node. It further pauses, unpauses or terminates the enactment of a workflow.

    The \texttt{WorkflowEngine} class is notified by the \texttt{WorkflowConsumer} and \texttt{WorkflowInstanceConsumer} on incoming messages. To alter the state of a running workflow instance, it contacts the swarm master directly. The more complex instantiation of a workflow is handled by the \texttt{WorkflowInstance} class.

    % subsubsection workflow_engine_service (end)

  \subsubsection{Developer Gateway} % (fold)
    \label{subs:developer_gateway}
    Since it only offers a unified access to the \ac{WfMS} and does not store any data itself, the developer gateway does not require any database. The service is realized in a two-tier architecture, with a backend part that handles requests to and responses from the various \ac{WfMS} services, and a frontend part that presents the received data to the developers and accepts their input.

    The only task of the backend is forwarding the user's requests to the message queue and the corresponding responses back to the user. The controller classes that are responsible for this (\texttt{ActivitesController}, \texttt{ControlFlowsController}, \texttt{DockerController}, \texttt{ProcessDefinitionsController}, \texttt{RolesController}, \texttt{ServersController}, \texttt{UsersController}, \texttt{WorkflowsController}) are thus very lean -- they only contain the logic to forward requests to suitable routing keys. Each of them inherits from the \texttt{ApplicationController}, which manages the messaging logic and gives access to a shared single connection to the \ac{MOM}.

    %API Gateway in this case features message endpoint pattern \cite[pp.~95-97]{Hohpe2004Enterprise}

    The \texttt{TemplatesController} is different from the other controller classes, as is not involved in forwarding requests, but serves the purpose to render and deliver the \ac{HTML} fragments required by the frontend.

    Following the API gateway pattern that is chosen in \ref{sub:user_interaction_with_the_system}, this service and the user gateway service are the only services that can be reached from outside of the \ac{WfMS}.
    % subsubsection developer_gateway (end)

  \subsubsection{User Gateway} % (fold)
    \label{subs:user_gateway}
    Analogous to the developer gateway, the user gateway provides access to those \ac{WfMS} services that are relevant to its users, that is, in the chosen setup, only the worklist management service.

    Due to the few responsibilities of this gateway, there are only two controller classes in this service: \texttt{WorklistItemsController}, which forwards \ac{CRUD} requests that concern worklist items and \texttt{WorklistController}, which provides the means to access all existing worklists.
    % subsubsection user_gateway (end)

  \subsubsection{Infrastructure Management Service} % (fold)
    \label{subs:environment_management_service}
    The infrastructure management service fetches and refines the information related to the swarms nodes.
    That is, it lists all nodes and can inform on their properties, (running) containers and available images.
    Supported by the \texttt{DockerHelper}, which provides the connections to the different nodes, the \texttt{EnvironmentManager} contains the required logic to fulfill these tasks. The \texttt{ServerConsumer} waits for relevant requests via the \ac{MOM}, instructs the \texttt{EnvironmentManager} accordingly, and returns the results. Further, there is a \texttt{Server} model class, which is used to structure the obtained information.

    Additionally to its role in the information retrieval, the \texttt{EnvironmentManager} subscribes to events of new nodes joining the swarm and launches the provisioning service on joining nodes.
    % subsubsection environment_management_service (end)

  \subsubsection{Registry} % (fold)
  \label{subs:registry}
    All solutions presented in Section~\ref{sec:docker_for_wf_execution} feature custom Docker images, be it workers or containerized activities or workflows. These images can contain information on business processes and other information whose disclosure should be avoided. In order to store and distribute such images, a private registry is thus required. A possible alternative for less sensitive images could be the utilization of a private remote repository on the Docker Hub.
  % subsubsection registry (end)

  \subsubsection{Provisioning Service} % (fold)
    \label{subs:provisioning_service}
    The objectives stated in \ref{sec:determination_of_objectives} include the reduction of administrative work. In order to prevent the user from having to distribute the Docker images required for the execution of workflows manually, a service should perform this task. This service should provision each machine with said images whenever such an image is created or updated. To do so, the \texttt{ImageConsumer} and \texttt{ServerConsumer} classes react to relevant events by invoking the appropriate Docker commands.

    The service could either run as an instance on each machine, performing the required Docker operations locally, or run on the Docker Swarm master machine as one instance and perform the operations remotely on all machines. The former variant enables all nodes to react concurrently to the event of a published image, while in the latter variant, the distribution would take place sequentially -- unless the service is implemented in a multi-threaded or multi-process way. While the idea of provisioning all nodes at the same time might be appealing, the workload imposed on the registry node by a big swarm should be considered.
    % subsubsection provisioning_service (end)
% subsection components (end)

